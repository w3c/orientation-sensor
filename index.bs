<pre class="metadata">
Title: Orientation Sensor
Status: ED
Level: 1
ED: https://w3c.github.io/orientation-sensor/
Shortname: orientation-sensor
TR: http://www.w3.org/TR/orientation-sensor/
Editor: Mikhail Pozdnyakov 78325, Intel Corporation, http://intel.com/
Editor: Alexander Shalamov 78335, Intel Corporation, https://intel.com/
Editor: Kenneth Rohde Christiansen      , Intel Corporation, http://intel.com/
Editor: Anssi Kostiainen 41974, Intel Corporation, http://intel.com/
Group: dap
Abstract:
  This specification defines concrete sensor interfaces to monitor the device's physical
  orientation in relation to <a>Earth's reference coordinate system</a>.
Version History: https://github.com/w3c/orientation-sensor/commits/gh-pages/index.bs
!Bug Reports: <a href="https://www.github.com/w3c/orientation-sensor/issues/new">via the w3c/orientation-sensor repository on GitHub</a>
Indent: 2
Repository: w3c/orientation-sensor
Markup Shorthands: markdown on
Inline Github Issues: true
!Test Suite: <a href="https://github.com/w3c/web-platform-tests/tree/master/orientation-sensor">web-platform-tests on GitHub</a>
Boilerplate: omit issues-index, omit conformance
Ignored Vars: sensor_instance
</pre>
<pre class="anchors">
urlPrefix: https://w3c.github.io/sensors; spec: GENERIC-SENSOR
  type: dfn
    text: activated
    text: construct a sensor object; url: construct-sensor-object
    text: default sensor
    text: equivalent
    text: high-level
    text: low-level
    text: latest reading
    text: sensor
    text: sensor-fusion
</pre>

<pre class="anchors">
urlPrefix: https://w3c.github.io/accelerometer; spec: ACCELEROMETER
  type: dfn
    text: acceleration
    text: local coordinate system
  type: interface
    text: Accelerometer; url: accelerometer
</pre>

<pre class="anchors">
urlPrefix: https://w3c.github.io/gyroscope; spec: GYROSCOPE
  type: dfn
    text: current angular velocity
  type: interface
    text: Gyroscope; url: gyroscope
</pre>

<pre class="anchors">
urlPrefix: https://w3c.github.io/magnetometer; spec: MAGNETOMETER
  type: dfn
    text: geomagnetic field
  type: interface
    text: Magnetometer; url: magnetometer
</pre>

<pre class="link-defaults">
spec:infra;
  type:dfn;
    text:list
spec:generic-sensor-1;
  type:enum-value;
    text:"activated"
</pre>

<pre class=biblio>
{
    "QUATERNIONS": {
        "authors": [
            "Kuipers, Jack B"
        ],
        "id": "QUATERNIONS",
        "href": "http://www.emis.ams.org/proceedings/Varna/vol1/GEOM09.pdf",
        "title": "Quaternions and rotation sequences. Vol. 66.",
        "date": "1999",
        "status": "Informational",
        "publisher": "Princeton university press"
    }
}
</pre>

Introduction {#intro}
============

The OrientationSensor API extends the Generic Sensor API [[GENERIC-SENSOR]]
to provide information that describes the device's physical orientation.

The base object describes the orientation in relation to <a>Earth's reference
coordinate system</a>, thus in a stationary three dimensional Cartesian
coordinate system.

Inheriting objects can describe the orientation in relation to other stationary
directions, such as true north, or even non stationary directions, like in
relation to a devices own z-position, drifting towards its latest most stable
z-position.

Examples {#examples}
========

<div class="example">
    <pre highlight="js">
    const sensor = new OrientationSensor();
    const mat4 = new Float32Array(16);
    sensor.start();
    
    sensor.onchange = () => {
      sensor.populateMatrix(mat4);
    };

    sensor.onerror = event => console.log(event.error.name, event.error.message);
    </pre>
</div>

Security and Privacy Considerations {#security-and-privacy}
===================================

There are no specific security and privacy considerations
beyond those described in the Generic Sensor API [[!GENERIC-SENSOR]].

Model {#model}
=====

The orientation sensors's associated {{Sensor}} subclass is the {{OrientationSensor}} class.

The orientation sensor is a [=high-level=] sensor which is created through [=sensor-fusion=]
of the [=low-level=] motion sensors:

 - accelerometer that measures [=acceleration=],
 - gyroscope that measures [=current angular velocity=], and
 - magnetometer that measures [=geomagnetic field=].

Note: Corresponding [=low-level=] sensors are defined in [[ACCELEROMETER]], [[GYROSCOPE]], and
[[MAGNETOMETER]]. Regardless, the fusion is platform specific and can happen in software or
hardware, i.e. on a sensor hub.

A [=latest reading=] per [=sensor=] of orientation type includes an [=map/entry=]
whose [=map/key=] is "quaternion" and whose [=map/value=] contains a four element [=list=].
The elements of the [=list=] are equal to components of a unit quaternion [[QUATERNIONS]]
[cos(θ/2), V<sub>x</sub> * sin(θ/2), V<sub>y</sub> * sin(θ/2), V<sub>z</sub> * sin(θ/2)] where V is the unit vector representing
the axis of rotation. The quaternion represents rotation of a device hosting motion sensors in relation to a <dfn>Earth's reference coordinate system</dfn> defined as a three
dimensional Cartesian coordinate system (x, y, z), where:

 - x-axis is a vector product of y.z that is tangential to the ground and points east.
 - y-axis is tangential to the ground and points towards magnetic north.
 - z-axis points towards the sky and is perpendicular to the plane made up of x and y axes.

The device's <a>local coordinate system</a> is the same as defined by [=low-level=] motion sensors.

Note: Figure below represents the case where device's <a>local coordinate system</a> and <a>Earth's reference coordinate system</a> are aligned, therefore,
orientation sensor's [=latest reading=] would represent 0 (rad) [[SI]] rotation about each axis.

<img src="device_orientation_sensor_coordinate_system.png" srcset="device_orientation_sensor_coordinate_system.svg" style="display: block;margin: auto;" alt="DeviceOrientationSensor coordinate system.">

API {#api}
===

The OrientationSensor Interface {#orientationsensor-interface}
-------------------------------------

<pre class="idl">
  [Constructor(optional SensorOptions sensorOptions)]
  interface OrientationSensor : Sensor {
    void populateQuaternion(Float32Array targetBuffer);
    void populateMatrix(Float32Array targetBuffer);
  };
</pre>

To <dfn>Construct a OrientationSensor Object</dfn> the user agent must invoke the
<a>construct a Sensor object</a> abstract operation.

### OrientationSensor.populateQuaternion() ### {#orientationsensor-populatequaternion}

<div algorithm="to populate quaternion">
The {{OrientationSensor/populateQuaternion()}} method must run these steps or their [=equivalent=]:
    1.  If |targetBuffer| is not of type {{Float32Array}}, [=throw=] a
        "{{SyntaxError!!exception}}" {{DOMException}} and abort these steps.
    1.  If |targetBuffer| is of type {{Float32Array}} with a size other than four, [=throw=] a
        "{{SyntaxError!!exception}}" {{DOMException}} and abort these steps.
    1.  If the value of |sensor_instance|.[=[[state]]=] is not <a enum-value>"activated"</a>,
        [=throw=] an "{{InvalidStateError!!exception}}" {{DOMException}} and abort these steps.
    1.  Run these sub-steps [=in parallel=]:
        1.  Let |quaternion| be the value of [=latest reading=]["quaternion"]
        1.  If |quaternion| is `null`, abort these steps.
        1.  Copy |quaternion| into |targetBuffer|
</div>

### OrientationSensor.populateMatrix() ### {#orientationsensor-populatematrix}

<div algorithm="to populate matrix">
The {{OrientationSensor/populateMatrix()}} method must run these steps or their [=equivalent=]:

</div>

Use-Cases and Requirements {#usecases-requirements}
==========================

Use cases {#usecases}
---------

    1. A compass monitor's the device's orientation relative to true north and aligns the compass heading in a three-dimensional space.
    1. A game uses the device's orientation relative to the ground as user input. For example, a ball-in-a-maze puzzle.
    1. A WebVR polyfill tracks the headset's (or mobile device's for mobile VR) orientation.
    1. A map application adjusts a two-dimensional map such that the device shows the map relative to the actual surroundings.

Functional requirements {#functional-requirements}
-----------------------

    1. The API must provide data that describes the device's physical orientation in a stationary 3D coordinate system.
    1. The API must provide data in representation that matches that of the WebGL interfaces and methods.
    1. The API must address the VR requirements for high performance and low motion-to-photon latency, and not
       introduce significant overhead over corresponding native platform APIs.
    1. The API must extend Generic Sensor and inherit its functionality and satisfy its requirements.

Non-functional requirements {#nonfunctional-requirements}
---------------------------

    1. The API must provide developer friendly and consistent higher level abstractions optimised for the common use cases.


Acknowledgements {#acknowledgements}
================

Tobie Langel for the work on Generic Sensor API.

Conformance {#conformance}
===========

Conformance requirements are expressed with a combination of
descriptive assertions and RFC 2119 terminology. The key words "MUST",
"MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT",
"RECOMMENDED", "MAY", and "OPTIONAL" in the normative parts of this
document are to be interpreted as described in RFC 2119.
However, for readability, these words do not appear in all uppercase
letters in this specification.

All of the text of this specification is normative except sections
explicitly marked as non-normative, examples, and notes. [[!RFC2119]]

A <dfn>conformant user agent</dfn> must implement all the requirements
listed in this specification that are applicable to user agents.

The IDL fragments in this specification must be interpreted as required for
conforming IDL fragments, as described in the Web IDL specification. [[!WEBIDL]]
